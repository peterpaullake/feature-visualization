import librosa
import numpy as np
import os
import torch
import torch.nn as nn
import torch.nn.functional as F

def lmap(*args):
    return list(map(*args))

def clear_dir(path):
    """Delete all the files in a directory."""
    for filename in os.listdir(path):
        os.remove(path + '/' + filename)

def prepare_datasets():
    """Create the training and test spectro-
    grams, and save them as .pt files."""
    audio_dir = 'free-spoken-digit-dataset/recordings'
    filenames = os.listdir(audio_dir)
    partition = {'train' : [], 'test' : []}
    labels = []
    def load_audio_file(filename):
        f = audio_dir + '/' + filename
        return librosa.load(f, res_type='kaiser_fast')[0]
    get_audio_file_size = lambda filename : len(load_audio_file(filename))
    max_size = max(lmap(get_audio_file_size, filenames))
    def pad_array(array, size):
        array2 = np.zeros(size)
        array2[:len(array)] = array
        return array2
    # clear the data directory
    clear_dir('data')
    # turn the audio files into examples
    for filename, i in zip(filenames, range(len(filenames))):
        x = int(filename[:-4].split('_')[-1])
        if x in range(5, 50):
            # this is a training example
            partition['train'].append(i)
        elif x in range(0, 5):
            # this is a test example
            partition['test'].append(i)
        array = pad_array(load_audio_file(filename), max_size)
        # array = load_audio_file(filename)
        stft = np.abs(librosa.core.stft(array, hop_length=16))
        tensor = torch.Tensor(stft)
        torch.save(tensor, 'data/%d.pt' % i)
        labels.append(int(filename.split('_')[0]))
    torch.save(partition, 'partition.pt')
    torch.save(labels, 'labels.pt')

class Dataset(torch.utils.data.Dataset):
    """This class loads in the spectrogram files
    generated by audio_classifier_cnn.py."""
    def __init__(self, ids, labels):
        self.ids = ids
        self.labels = labels

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, index):
        i = self.ids[index]
        x = torch.load('data/%d.pt' % i)
        y = self.labels[i]
        return x, y

def load_datasets():
    """Return datasets to be used with torch.utils.data.DataLoader."""
    partition = torch.load('partition.pt')
    labels = torch.load('labels.pt')
    train = Dataset(partition['train'], labels)
    test = Dataset(partition['test'], labels)
    return train, test

class Model(nn.Module):
    """CNN for classifying spectrograms of spoken digits."""
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 5, kernel_size=8)
        self.conv2 = nn.Conv2d(5, 10, kernel_size=8)
        self.conv3 = nn.Conv2d(10, 10, kernel_size=3)
        self.fc1 = nn.Linear(51200, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, batch, conv_id=None, channel_id=0):
        """If conv_id is None, return the output of the
        model normally. Otherwise, return the mean of the
        channel specified by conv_id and channel_id."""
        def get_layer_mean(x):
            num_filters = x.shape[1]
            img_size = x.shape[2] * x.shape[3]
            means = x.view(-1, num_filters, img_size).mean(dim=2)
            return means[0][channel_id]
        
        out = batch.view(-1, 1, *batch.shape[-2:])
        
        out = self.conv1(out)
        out = F.max_pool2d(out, kernel_size=4)
        out = F.relu(out)
        if conv_id == 0:
            return get_layer_mean(out)

        out = self.conv2(out)
        out = F.max_pool2d(out, kernel_size=3)
        out = F.relu(out)
        if conv_id == 1:
            return get_layer_mean(out)

        out = self.conv3(out)
        out = F.max_pool2d(out, kernel_size=2)
        out = F.relu(out)
        if conv_id == 2:
            return get_layer_mean(out)

        out = out.view(-1, 51200)
        out = self.fc1(out)
        out = F.relu(out)
        out = F.dropout(out, training=self.training)

        out = self.fc2(out)
        return out

def compute_loss(model, batch, labels):
    return F.cross_entropy(model(batch), labels)

def compute_accuracy(model, dataset, batch_size=4):
    s = 0
    n = 0
    generator = torch.utils.data.DataLoader(dataset, batch_size=batch_size)
    for batch, labels in generator:
        y = F.softmax(model(batch), dim=1).max(dim=1).indices.detach().numpy()
        correctness = (y == np.array(labels))
        s += correctness.sum()
        n += len(correctness)
    return s / n

def train_model(model, num_epochs=6, batch_size=4):
    train = load_datasets()[0]
    generator = torch.utils.data.DataLoader(train, batch_size=batch_size)
    num_batches = int(np.ceil(len(train) / batch_size))
    optimizer = torch.optim.Adam(model.parameters())
    for epoch in range(num_epochs):
        print('starting epoch %d/%d' % (epoch + 1, num_epochs))
        for i, (batch, labels) in zip(range(num_batches), generator):
            # plug the batch into the model
            loss = compute_loss(model, batch, labels)
            # step the parameters in the right direction
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            # print batch loss and epoch progess
            if i % 10 == 0:
                progress = (i + 1) / num_batches * 100
                print('\tbatch loss:     %.3f' % loss)
                print('\tepoch progress: %.3f%%' % progress)
    model.eval()
    return model

def save_model(model, path='model.pt'):
    torch.save(model.state_dict(), path)

def load_model(create_model_instance=lambda : Model(), path='model.pt'):
    model = create_model_instance()
    model.load_state_dict(torch.load(path))
    model.eval()
    return model

def main():
    print('creating spectrograms')
    prepare_datasets()
    print('training model')
    model = train_model(Model())
    print('saving model')
    save_model(model)

main()
